{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91094326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273b2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "block_size is the max input length of the transformer.\n",
    "If the actual input length is less than block_size, we will pad them with padding ids 0.\n",
    "\n",
    "token_id_list is a list consisting of token ids of each sequence. \n",
    "For example, \n",
    "token_id_list = [[1,2,3,4,5,6],\n",
    " [1,2,3,4],\n",
    " [1,2,3]]\n",
    "is a list of sequences with length 6,4,3\n",
    "\n",
    "input_length_list is a list consisting of input length of each sequence. The rest is CoT.\n",
    "For example, \n",
    "input_length_list = [2,2,2]\n",
    "1,2 are always input\n",
    "'''\n",
    "block_size = 8\n",
    "token_id_list = [[1,2,3,4,5,6],[1,2,3,4],[1,2,3]]\n",
    "input_length_list = [2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4399fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "choose between train and val\n",
    "'''\n",
    "# filename = 'val'\n",
    "filename = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b0a8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 16\n",
    "p = 7\n",
    "N = 1000000\n",
    "random_list = np.random.randint(low = 1,high =8, size = (N,8), dtype = np.int8)\n",
    "partial_sum_random_list = ( np.cumsum(random_list, axis = 1) -1) % p + 1\n",
    "input_length_list = np.random.randint(low = 1,high =block_size//2, size = (N,), dtype = np.int8)\n",
    "token_id_list = []\n",
    "for i in range(N):\n",
    "    current_input_tokens = random_list[i][:input_length_list[i]]\n",
    "    current_label_tokens = partial_sum_random_list[i][:input_length_list[i]]\n",
    "    token_id_list.append(list(current_input_tokens) + [-2] + list(current_label_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a04abf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, -2, 6]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65db06ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [00:07, 128345.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dtype = np.int8\n",
    "arr = np.memmap(filename + '.bin', dtype=dtype, mode='write', shape=(block_size * len(token_id_list)))\n",
    "arr_label = np.memmap(filename + '_label.bin', dtype=dtype, mode='write', shape=(block_size * len(token_id_list)))\n",
    "print(f\"writing {filename}...\")\n",
    "for jj, example in tqdm(enumerate(token_id_list)):\n",
    "    arr[jj * block_size : jj * block_size + len(example)] = example\n",
    "    arr[jj * block_size + len(example) : (jj + 1) * block_size] = 0\n",
    "    arr_label[jj * block_size : jj * block_size + input_length_list[jj]] = -1\n",
    "    arr_label[jj * block_size + input_length_list[jj]  : jj * block_size + len(example) - 1] = example[input_length_list[jj] +1 :]\n",
    "    arr_label[jj * block_size + len(example) - 1 : (jj + 1) * block_size] = -1\n",
    "    # pad to bock_size\n",
    "arr.flush()\n",
    "arr_label.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "194b1967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 6, -2,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         1,  6,  3,  5,  1,  5, -2,  1,  7,  3,  1,  2,  7,  0,  0,  0,\n",
       "         7,  5,  5,  3, -2,  7,  5,  3,  6,  0,  0,  0,  0,  0,  0,  0,\n",
       "         2,  3, -2,  2,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         5,  1,  5,  2,  1,  6,  7, -2,  5,  6,  4,  6,  7,  6,  6,  0,\n",
       "         7, -2,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         4, -2,  4,  0], dtype=int8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a507a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', dataset)\n",
    "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "train_label = np.memmap(os.path.join(data_dir, 'train_label.bin'), dtype=np.int16, mode='r')\n",
    "val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n",
    "val_label = np.memmap(os.path.join(data_dir, 'val_label.bin'), dtype=np.int16, mode='r')\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    label = train_label if split == 'train' else val_label\n",
    "    ix = torch.randint(len(data) // block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i * block_size:(i+1)*block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((label[i * block_size:(i+1)*block_size]).astype(np.int64)) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe38724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(408.9389, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input = torch.randn(10, 10000, requires_grad=True)*100\n",
    "target = torch.randint(10000, (10,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77072763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d1165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt-m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ce87cd7785718493854dd4fd9b106cf8caf02fcaf29cf2056c1f0b44ba5db32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
